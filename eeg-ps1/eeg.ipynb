{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Problem Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mne import set_log_level\n",
    "set_log_level(verbose=False)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment will consist of 3 parts:\n",
    "- Part 1: ERP analysis\n",
    "- Part 2: Time-frequency analysis\n",
    "- Part 3: Experimental design question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Instructions\n",
    "\n",
    "In this problem set, you will be performing an ERP analysis and time-frequency analysis on a preprocessed dataset. First let's describe the task in greater detail. \n",
    "\n",
    "This experiment is based on the oddball paradigm used in [Luck et al., (2009)](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2009.00817.x). In the oddball paradigm, a letter or digit was presented every 1100-1500 ms. Subjects were instructed to press a button with one hand for digits and with the other hand for letters. For a given trial block, either the letters or the digits were rare (20%) and the other category was frequent (80%). The stimulus category (digits or letters), the probability (80% or 20%) and the hand used for response (left or right) were counterbalanced, leading to 8 experimental conditions. The probability manipulation was designed to isolate the probability-sensitive P300 component. Different event codes were used for the digits when they were rare (`20_Dig_L` for response with left hand, `20_Dig_R` for response with right), the digits when they were frequent (`80_Dig_L`, `80_Dig_R`), the letters when they were rare (`20_Let_L`, `20_Let_R`), and the letters when they were frequent (`80_Let_L`, `80_Let_R`). These event codes are summarized below:\n",
    "\n",
    "|Left/Right|Rare|Frequent|\n",
    "|---|---|---|\n",
    "|Digits|20_Dig_L/20_Dig_R|80_Dig_L/80_Dig_R|\n",
    "|Letters|20_Let_L/20_Let_R|80_Let_L/80_Let_R|\n",
    "\n",
    "The P300 is a neural marker of surprise. As such, we expect a larger P300 during the rare trials than for the frequent trials. In this notebook, you will analyze the difference (if any) in P300s between conditions. Specifically, you will (1a) perform permutation testing, and (1b) visualize the evoked potentials. After this, you will (2) do a time-frequency analysis to identify a signature of conflict in the theta (4-8 Hz) band.\n",
    "\n",
    "We've included the script used for preprocessing (`eeg-preprocessing.ipynb`) and an inspector (`eeg-inspector.ipynb`) if you'd like to take a closer look at the data.\n",
    "\n",
    "We begin by loading in the epoched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import read_epochs\n",
    "\n",
    "## Load epochs.\n",
    "epochs = read_epochs('sub-01_task-digitsymbol-epo.fif', preload=True, verbose=False)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a: Event Related Potential Analysis\n",
    "\n",
    "In the following, you will look to find the P300 in the evoked potentials of each condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evoked Potentials\n",
    "\n",
    "First, make two evoked potentials:\n",
    "- *frequent*: an average of all the frequent (80) trials, collapsing over symbol and hand.\n",
    "- *rare*: an average of all the rare (20) trials, collapsing over symbol and hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Evoked Potentials\n",
    "Using `mne.viz.plot_evoked_topo`, plot a comparison of all the evoked potentials across the scalp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Is there an obvious P300?\n",
    "\n",
    "> &nbsp;\n",
    "\n",
    "**Q**: If there is a P300, is it prominent everywhere?\n",
    "\n",
    "> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topographic Plots\n",
    "Make topographic plots for the **difference wave**  Remember that the P300 should start around 300 ms and persist for many hundreds of milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: If present, when is the P300 most prominent?\n",
    "\n",
    "> &nbsp;\n",
    "\n",
    "**Q**: If present, where is the P300 most prominent?\n",
    "\n",
    "> &nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b: Replication + Permutation Testing\n",
    "\n",
    "In this final step, we will formalize our analysis by replicating and extending Figure 2 from [Luck et al., (2009)](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2009.00817.x). To do so, we will perform permutation testing, testing for differences in the amplitude of the P300 between conditions across three sets of channels.\n",
    "\n",
    "First, make two separate epoch objects:\n",
    "- *frequent*: all the frequent (80)\n",
    "- *rare*: all the rare (20) trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, find the corresponding indices for the following sets of channels. Find the indices using `mne.pick_channels`. \n",
    "- frontal: F1, Fz, F2\n",
    "- central: C3, Cz, C4\n",
    "- parietal: P3, Pz, P4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the permutation testing code presented in the `eeg-02` demo, write a *for loop* that performs the following for each channel set:\n",
    "\n",
    "1. Extracts the trials by channel set and condition (frequent, rare).\n",
    "2. Average over the channels.\n",
    "3. Performs permutation testing with 1024 permutations.\n",
    "4. Plots the evoked potential (i.e. average over trials) per condition and highlights significant clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "In the previous section, you measured the P300 in response to rare trials. During rare trials, participants need to inhibit a prepotent motor response (i.e. responding as if they saw a frequent trial). The need for motor inhibition is often said to generate a conflict signal. In scalp EEG, conflict signals are detectable as increases in non-phase-locked theta (4-8 Hz) power. In this final section, you will follow the steps as detailed in [Cohen & Donner (2013)](https://www.physiology.org/doi/full/10.1152/jn.00479.2013) to measure the theta signature of conflict in rare trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Spectral Decomposition\n",
    "\n",
    "With the epochs loaded, you will perform a spectral decomposition on the data to measure the time-frequency content of the data. Following [Cohen & Donner (2013)](https://www.physiology.org/doi/full/10.1152/jn.00479.2013), you will use Morlet wavelet decomposition. \n",
    "\n",
    "First you need to define the frequencies you want to measure. Using `np.logspace`, generate a vector of 12 logarithmically-spaced frequencies beginning at 4 Hz and ending at 30 Hz. (Note: If you do this correct, your vector should start and end with 4 and 30, respectively.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, you are going to perform the spectral decomposition. The challenge is that you will need to measure non-phase-locked power. In other words, you are decomposing the epochs after the evoked potential has been subtracted. Importantly, this subtraction must occur within each condition. \n",
    "\n",
    "To assist you, we have started a for loop. In each cycle of the for loop, you will perform the following steps:\n",
    "\n",
    "1. Make copy of the per-condition epochs.\n",
    "2. Subtract evoked potential from copy.\n",
    "3. Perform Morlet wavelet decomposition on the evoked-subtracted copy using the following parameters:\n",
    "    - `freqs`: as defined above\n",
    "    - `n_cycles`: 3\n",
    "    - `return_itc`: False\n",
    "4. Apply a baseline transformation to the power estimates making sure to:\n",
    "    - Baseline correct (-0.1, 0.0)\n",
    "    - Convert power into decibels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet\n",
    "\n",
    "## Define conditions.\n",
    "conditions = ['20_Dig_L', '20_Dig_R', '20_Let_L', '20_Let_R',\n",
    "              '80_Dig_L', '80_Dig_R', '80_Let_L', '80_Let_R']\n",
    "\n",
    "## Main loop.\n",
    "spectral = []\n",
    "for k in conditions:\n",
    "\n",
    "    ## Make temporary copy.\n",
    "    trials = epochs[k].copy()\n",
    "    \n",
    "    ## Subtract evoked.\n",
    "    # <code goes here>\n",
    "    \n",
    "    ## Perform Morlet-based time-frequency decomposition.\n",
    "    # <code goes here>\n",
    "    \n",
    "    ## Apply baseline transformation.\n",
    "    # <code goes here>\n",
    "    \n",
    "    ## Store.\n",
    "    spectral.append( \"\"\"<code goes here>\"\"\" )\n",
    "    \n",
    "## Convert to NumPy array.\n",
    "spectral = np.array(spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2b: Compute Averages \n",
    "\n",
    "Using the power estimates defined above, create an average spectrogram for the frequent and rare trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2c: Visualize Spectrograms\n",
    "\n",
    "#### Frequent Trials\n",
    "\n",
    "Plot the spectrogram of the frequent trials for channel FCz using your favorite heatmap function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rare Trials\n",
    "\n",
    "Plot the spectrogram of the rare trials for channel FCz using your favorite heatmap function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rare - Frequent Trials\n",
    "\n",
    "Plot the spectrogram of the rare - frequent trials for channel FCz using your favorite heatmap function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Is there an increase in theta power between frequent and rare trials? If so, where?\n",
    "\n",
    "> &nbsp;\n",
    "\n",
    "**Q:** Does the plot above resemble the non-phase-locked power from the midfrontal electrode (FCz) in Figure 2 of [Cohen & Donner (2013)](https://www.physiology.org/doi/full/10.1152/jn.00479.2013)?\n",
    "\n",
    "> &nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "The final question on this problem set is about experimental design.\n",
    "\n",
    "You've just received a manuscript for review from an eminent  neuroeconomics researcher who claims to have discovered an ERP that registers when someone learns about a potentially lucrative financial opportunity. You turn a critical eye towards the paper, and see that the results have probably been over-interpreted. \n",
    "\n",
    "Here is the design: A computer presented numbers on a screen representing the quantity that may be won or lost on a given trial. If the amount was positive, the numbers were green. If the amount was negative, the numbers were red. The subject was asked to press a button if they wanted to “place a bet”. The cost of a bet was \\\\$0.01. If the subject chose to place a bet, two seconds after their response they were informed as to whether they won. 80% of the time they won the promised amount, but 20% of the time they won or lost a random amount between -\\\\$10 and \\\\$10. The average payout on positive trials was \\\\$6, and the average loss on negative trials was \\\\$5. A payout or loss only occurred if the subject placed a bet. To simulate the negative bias of the financial media, only 10% of trials were positive, while 90% were negative. \n",
    "\n",
    "The results: Behaviorally, subjects bet on 95% of positive trials and only 1% of negative trials. There is an ERP for the green positive numbers that peaks at about 210 ms over parietal cortex. The stimulus-locked ERP pattern evoked by the colored number looks like this: \n",
    "\n",
    "![](images/part3-figure.png)\n",
    "\n",
    "(Note that negative voltages are plotted here as positive on the Y axis as per traditional practice -- and that's not a mistake or a confound.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Name at least two possible confounds with this experiment. (One extra-credit point can be earned by naming three confounds.)\n",
    "\n",
    "> &nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
